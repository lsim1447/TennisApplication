%!TEX root = dolgozat.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Az alkalmazás felépítése}\label{ch:felepites}

\begin{osszefoglal}
	Mint ahogyan az előző fejezetekből is megtudhattuk, az alkalmazás lényege, hogy egy, az általunk kiválasztott mérkőzésről, a kiválasztott játékosok formájától és addigi statisztikáiktól függően egy jóslatot tárjon elénk, amelyben a játékosok százalékos győzelmi esélyeit jeleníti meg. 
	\paragraph{}
	Ez az alkalmazás két fő részből áll, amelyek közül az egyik szintén tovább bontható:
	\begin{enumerate}
		\item[•] Kliens oldali rész
		\item[•] Szerver oldali rész
		\begin{enumerate}
			\item[•] Spring: adatbázis műveletek
			\item[•] Python: neurális háló
		\end{enumerate}
	\end{enumerate}
\end{osszefoglal}

\paragraph{}
Az alkalmazás működését tekintve a következőképpen működik: a felületről érkező kéréseket a Java szerver kezeli, majd a neurális hálóval kapcsolatos műveletek elvégzése érdekében a Java szerver egy kérést küld a Python szerverünknek, amely a megfelelő utasítások végrehajtása során válaszol a Java szerverünknek, majd az a kliens oldalon futó szervernek, amely megjeleníti a kapott információkat.

\paragraph{}
A szerverek közti kommunikáció megkönnyítése érdekében a Java oldalon történő tréning adatok kiszámítását követően az adatokat egy JSON alakú fájlba írjuk, majd egy kérést küldünk a Python szerverünknek az állomány nevével, amely ezt követően beolvassa az adott állomány tartalmát, majd elvégzi a kért műveleteket.

\section{A kliens oldal}
\paragraph{}
A kliens oldal a  React keretrendszer által lett megvalósítva. Az alkalmazás lehetőséget nyújt a felhasználók számára, hogy a tennis 4 nagy tornájának (Grand slams) a nyerteseit, mérkőzéseit megtekintjük táblázatos formában. Ugyanakkor lehetőségünk van tetszés szerint a tornák neve alapján is rákeresni bizonyos eseményekre, tornákra. 
\paragraph{}
Ugyanúgy mint a tornák esetén, a játékosok esetében is lehetőségünk van a név szerinti keresésre, ahol a kiválasztott játékos karrierjének összes fontosabb mozzanatáról találhatunk néhány érdekesebb statisztikai adatot.
\paragraph{}
Az alkalmazás legérdekesebb és egyik legfontosabb része, a játékosok párba/szembeállítása, amikor az egymással szembeni, egymáshoz viszonyított statisztikai adatokat tárja elénk az alkamazás. Ennél a résznél van lehetőségünk a párharc kimenetelének a "megjósoltatására" is.

\subsection{CSS keretrendszer - Bootstrap}
\paragraph{}
Az alkalmazás reszponzív, azaz egy olyan alkalmazás, amely törekszik arra, hogy optimális megjelenítést biztosítson a könnyű olvashatóság és egyszerű navigációval egyidőben. Ezt különböző eszközökön egyaránt próbálja fenntartani az asztali számítógépek képernyőjétől a mobiltelefonok kijelzőjéig egyaránt. Azaz a webalkalmazás alkalmazkodik az őt használó eszköz méreteihez:
\begin{enumerate}
\item[•] A rugalmas felosztású koncepció alapján a honlap minden elemének mérete százalékosan, relatívan van meghatározva.
\item[•] A flexibilis képek úgyszintén a befoglaló elemhez képest, százalékosan határozódnak meg.
\item[•] A media query alkalmazásával megvalósíthatjuk, hogy a weboldalon mindig olyan CSS szabályok lépjenek érvénybe, amelyek a megjelenítő eszközön optimálisak.
\end{enumerate}

\paragraph{}
A Bootstrap\footnote{A Bootstrap hivatalos oldala: https://getbootstrap.com/} egy olyan eszközkészletet kínál, amely előre megírt, multifunkcionálisan alkalmazható, aminek a segítségével átláthatóbban, gyorsabban és hatékonyabban dolgozhatunk. A CSS tulajdonságok és a HTML struktúra mellett számos JavaScript bővítménnyel is rendelkezik, melyek igen rugalmasak!

\begin{lstlisting}[caption=Responsive webtervezés - Bootstrap keretrendszer]
<ul className="nav nav-pills mb-3" id="pills-tab" role="tablist">
  <li className="nav-item">
    <a className="nav-link active font-weight-bold" id="pills-latest-tab" data-toggle="pill" href="#pills-latest" role="tab" aria-controls="pills-latest" aria-selected="true"> 
      Latest 
    </a>
  </li>
  <li className="nav-item">
    <a className="nav-link font-weight-bold" id="pills-grand-slam-tab" data-toggle="pill" href="#pills-grand-slam" role="tab" aria-controls="pills-grand-slam" aria-selected="false"> 
      Grand Slams 
    </a>
  </li>
</ul>
\end{lstlisting}

\paragraph{} A kliensoldal felépítése során fontos szempontnak számított az újrafelhasználható komponensek használata, ezért az alkamazásunkban több helyen is ugyanazokat a komponenseket használtuk, ezáltal is törekedve a kód méretének minimalizálására.

\section{Szerver oldal}
\subsection{Java - Spring}
\paragraph{}
Az alkalmazásunkban a szerver oldal Java-Spring része felelős az adatbázissal való kommunikációért. Itt hajtódnak végre az adatbázisból nyert adatok feldolgozásai annak érdekében, hogy olyan adatokat kapjunk, amelyeket a neurális háló számára tréning adatként bocsáthatunk.

\paragraph{}
A projekt megvalósítása során az adatbázis és az adatbázis séma közti függetlenség kialakítása érdekében ORM keretrendszert használtunk, pontosabban RedHat által fejlesztett Hibernate-t. A Hibernate egy objektum-relációs leképezést megvalósító programkönyvtár Java platformra, amelynek segítségével relációs adatbázisok tábláit és osztályokat tudunk egymásba leképezni, általa az adatbázisban lévő rekordokat úgy kezelhetjük mint objektumok. A leképzések az osztályok és az adattáblák között annotációk (mint ahogyan a projektben is használtuk) és XML állományok által is megvalósítható. 

\paragraph{}
\begin{figure}[t]
  \centering
  \pgfimage[width=1.1\linewidth]{images/database}
  \caption[Az adatbázis]%
  { Az adatbázis szerkezete }
  \label{fig:ALAP:sm1}
\end{figure}
\paragraph{}
Az adatbázisból lekért adatokat olyan értékekké(input adatokká) kell alakítanunk, hogy a neurális háló számára felhasználhatóak legyenek. Ez a [0,1] intervallumot jelenti a mi esetünkben. Ezeket az átalakítások a következőképpen történnek: a kiválasztott játékosoknak lekérjük az utolsó, már előre meghatározott számú mérkőzéseiket, majd különböző valószinűségeket, statisztikákat számolunk mindkét játékos számára (5.2-es kódrészlet).

\begin{lstlisting}[caption= Egy játékos utolsó mérkőzéseinek győzelmi rátája]
private double convertToPercentage(List<Match> matches, Player player){
  if (matches.size() == 0) return 0.00;
  long counter = matches.stream()
    .filter(match -> match.getWinnerPlayer().getPlayer_id() == player.getPlayer_id())
    .count();

  return (matches.size() > 0) ? 
    Double.parseDouble(df.format((double) counter / (double) matches.size())) : 
    0.0;
}
\end{lstlisting}

\begin{tabular}{ |p{2cm}||p{6cm}|p{6cm}|  }
 \hline
 \multicolumn{3}{|c|}{Az input adatok listája} \\
 \hline
  Number & Name & Level \\
 \hline
 1   & Winning Rate                  & ALL + Tournament + Surface \\
 2   & 1 vs 1 Winning Rate           & ALL + Tournament + Surface \\
 3   & Round experience              & ALL + Tournament + Surface \\
 4   & Match Duration Avg            & Tournament  \\
 5   & Service Points Won Rate       & ALL + Tournament + Surface \\
 6   & First Serve In Rate           & ALL + Tournament + Surface \\
 7   & First Serve Won Rate          & ALL + Tournament + Surface \\
 8   & Break Points Converted Rate   & ALL + Tournament + Surface \\
 9   & Break Points Saved Rate       & ALL + Tournament + Surface \\
 10  & Second Serve Points Won Rate  & ALL + Tournament + Surface \\
 11  & Second Serve Return Won Rate  & ALL + Tournament + Surface \\
 12  & Games Won Rate                & ALL + Tournament + Surface \\
 13  & Sets Won Rate                 & ALL + Tournament + Surface \\
 \hline
\end{tabular}

\paragraph{}
A fenti táblázatban azok a szempontok vannak  felsorolva, amelyeket a mérkőzések kimenetelének megjósolása alkalmával figyelembe vettünk. A táblázat harmadik oszlopa azt mutatja, hogy az adott "statisztikai mutatót" a játékos összes meccsére (ALL), az adott tornán lejátszott meccseire (Tournament) vagy az adott talajon lejátszott meccseire (Surface) számítottuk ki és alkalmaztunk.

\begin{lstlisting}[caption= A második adogatások utáni pontok győzelmi rátája fogadóként]
public double getSecondServeReturnWonRate(List<Stats> playerStats, Player player){
  playerStats = playerStats.stream()
    .filter(st -> !((double)st.getWinner_second_serve_return_total() < 0.0001 || (double) st.getLoser_second_serve_return_total() < 0.0001))
    .collect(Collectors.toList());

  double playerSecondServeReturnWonRate = (playerStats.stream()
    .map(s -> {
      if(s.getMatch().getWinnerPlayer().getPlayerSlug().equals(player.getPlayerSlug())){
        return s.getWinner_second_serve_return_won() / (double)s.getWinner_second_serve_return_total();
      } else {
        return stat.getLoser_second_serve_return_won() / (double)s.getLoser_second_serve_return_total();
      }
    })
    .reduce(0.00, (a, b) -> a + b));

  if (playerStats.size() == 0) {
    throw new NumberFormatException();
  }

  playerSecondServeReturnWonRate = playerSecondServeReturnWonRate / (double) playerStats.size();
  return Double.parseDouble(df.format(playerSecondServeReturnWonRate));
}
\end{lstlisting}

\begin{lstlisting}[caption= Az adatbázisban talált mérkőzések training adatokká való átalakítása]
    private List<TrainData> getTrainData(List<Match> matches){
        return matches.stream()
                .filter(match -> getInputs(match) != null)
                .map(match -> new TrainData(getInputs(match), getOutputs(match)))
                .collect(Collectors.toList());
    }
\end{lstlisting}

\paragraph{}
Minden mérkőzés esetén, amikor a neki megfelelő input adatok kiszámításán dolgozunk, csak az előtte lévő X mérkőzés adatait vesszük figyelembe. A mérkőzések közül csak azon meccsek maradnak a trainghez felhasznált mérkőzések között, amelyek teljesítenek bizonyos feltételeket, például egy minimum mérkőzésszám az adott játékos karrierjében, az adott talajon, tornán stb. Ez azért fontos, mivel a beválogatás során a legmegfelelőbb adatokat érdemes megtartanunk, hogy minél jobb eredményeket érhessünk el.

\paragraph{}
Abban az esetben, ha az adott mérkőzés nem felel meg az elvárásoknak, a "getInputs" metódus null értéket fog visszatéríteni, és mint ahogyan az 5.4-as kódrészletben is láthatjuk, az ilyen mérkőzések nem fognak bekerülni a training adataink közé.

\paragraph{}
Annak érdekében, hogy a training adatok létrehozásának folyamatát felgyorsítsuk, a játékosok mérkőzéseit változókba (5.5-ös kódrészlet) mentettük, amely azért lehet hasznos, mert a mérkőzések egyenként való feldolgozása alkalmával minden játékos mérkőzéseit így egyetlen alkalommal kell lekérnünk az adatbázisból, amely lényegesen hozzájárul a futásidő minimalizálásához (5.6-os kódrészlet).

\begin{lstlisting}[caption=A futásidő minimalizálásához használt HashMap-ek listája]
    private HashMap<String, List<Match>> matchMap = new HashMap<>();
    private HashMap<String, List<Match>> matchMapOnSurface = new HashMap<>();
    private HashMap<String, List<Match>> matchMapHeadToHead = new HashMap<>();
    private HashMap<String, List<Match>> matchMapHeadToHeadOnSurface = new HashMap<>();
    private HashMap<String, List<Match>> matchMapOnTournament = new HashMap<>();
\end{lstlisting}

\begin{lstlisting}[caption=A győztes játékos meccseinek inicializálása]
List<Match> winnerPlayerAllMatches;

if (matchMap.containsKey(winnerPlayer.getPlayerSlug())) {
  winnerPlayerAllMatches = matchMap.get(winnerPlayer.getPlayerSlug());
} else {
  winnerPlayerAllMatches = (List<Match>) matchService.findAllMatchesByPlayerName(winnerPlayer.getFirstName(), winnerPlayer.getLastName());
  matchMap.put(winnerPlayer.getPlayerSlug(), winnerPlayerAllMatches);
}
\end{lstlisting}

\subsection{Python - Neurális hálók}
\paragraph{}
A második fejezetben nagyon röviden már elkezdtük bemutatni a gépi tanulás és a neurális hálók világát, viszont lássuk kicsit részletesebben is, és hogy hogyan is használtuk fel mindezt az alkalmazásunkban.

\paragraph{}
Ahhoz, hogy jól megérthessük azt, hogy mi is az a neurális háló, tegyünk egy lépést hátra és beszéljünk egy kicsit a mesterséges neuronról, ismertebb nevén a perceptronról. A perceptront az 1950-es és 1960-as években Frank Rosenblatt tudós fejlesztette ki, inspirálódva Warren McCulloch és Walter Pitts munkájából. Manapság már gyakrabban használják a mesterséges neuron más modelljeit, például a sigmoid neuront, de hogy jobban megérthetssük annak működését, először lássuk hogyan is működik a perceptron.

\paragraph{}
A perceptron működése viszonylag egyszerű (2.3-as ábra), a több bemenő adatból (inputs: x1, x2, ...), egyetlen kimeneti értéket állít elő (output). A bemeneti értékek mellett súlyaink is vannak (w1, w2, ...), amelyek a bemeneti adatok fontosságát jelzik a kimenetre nézve. Minél nagyobb súllyal látunk el egy bemeneti értéket, annál fontosabb és nagyobb ráhatással lesz a kimenetünkre. A neuron kimenete 0 vagy 1, attól függően, hogy a bemeneti értékek és a nekik megfelelő súlyok szorzatösszege kisebb vagy nagyobb egy bizonyos küszöbértéknél (threshold value).

\paragraph{}
Történetesen amikor definiálunk egy perceptront, akkor annak a perceptronnak csak egyetlen kimenetele van. Egy háló esetén úgy tűnhet, hogy több is van, viszont még mindig igaz az az állítás, hogy csak egyetlen kimenet van. Viszont egy perceptron kimenete lehet több más perceptron bemenete egyaránt.

\paragraph{}
Annak érdekében, hogy megpróbáljuk leegyszerűsíteni a perceptron "szabályát", bevezethetjük a "bias" fogalmát (jelöljük b-vel), amelynek értéke feleljen meg a küszöbérték ellentettjével. Ennek következtében a képletünk a következőképpen alakul:
\[ 
Output= \left\{
\begin{array}{ll}
      0, w*x + b <= 0 \\
      1, w*x + b >= 0 \\
\end{array} 
\right. 
\]

Erre a bias-re tulajdonképpen tekinthetünk úgy, mint egy olyan mértékre, amely megmondja, hogy milyen könnyen adhatja a perceptron számunkra az 1-es értéket. Mint ahogyan a képletből is láthatjuk, egy nagyon nagy bias értékkel nagyon egyszerűen tud a perceptronunk 1-es értéket visszatériteni. Természetesen a fordítottja igaz egy nagyon nagy negatív értékre.

\paragraph{}
Tételezzük fel, hogy az alkalmazásunkban perceptronokból felépített hálózatot használunk. Logikusan úgy gondoljuk, hogy egy teniszmérkőzés esetén, ha csak egy kis mértékben változtatjuk meg például az első adogatások sikerességének a súlyát és a bias értékét, akkor az egy kis eredménymódosulással járhat mindössze, például a két játékos győzelmi esélye változik valamelyik irányba 1-2 százalékkal. A probléma az, hogy egy kis változtatás ezeken az értékeken egy nagyon nagy bonyodalmat is okozhat olyan értelemben, hogy egy egyáltalán nem várt, irreális eredményt kapunk a végén. Ezeknek a fajta hibáknak a nagyobb eséllyel való elkerülése érdekében vezették be a sigmoid neuronokat.

\paragraph{}
A sigmoid neuronok hasonlítanak a perceptronokhoz, viszont különböznek egyetlen fontos tulajdonságban: általuk egy súlyon/bias-en végzett apróbb módosítás mindössze kisebb változással járhat a kimenetre nézve. Ezt úgy valósítja meg, hogy míg a perceptron esetében a kimeneti érték 0 vagy 1 lehet, addig a sigmoid neuron esetében a kimenet bármilyen érték lehet a [0,1] intervallumban, például 0.7496 is. A sigmoid függvény alakját már a második fejezetben is bemutattuk:
$$h_ \theta (x) =  \frac{\mathrm{1} }{\mathrm{1} + e^- \theta^Tx }  $$ 
Szóval bizonyos műveletek elvégzése után a sigmoid neuron kimenete  a következőképpen alakul (az x1, x2 ... bemeneti adatokat, a w1,w2, ... súlyokat és "b" a bias értéket jelöli):

$$\frac{\mathrm{1} }{\mathrm{1} + exp(-\sum_{i=0}^{+n} (w_j * x_j - b)) }  $$ 

\subsubsection{Alkalmazás}
\paragraph{}


\begin{lstlisting}[caption=A neurális háló felépítése]
NR_OF_INPUTS = 90      // a bemenő adatok száma = INPUTS
NR_OF_LAY = 20         // az első layeren lévő neuronok száma
NR_OF_INNER_LAY = 8    // a második layeren lévő neuronok száma
NR_OF_OUTPUTS = 2      // a kimenő adatok száma = OUTPUTS
\end{lstlisting}

\begin{lstlisting}[caption=A szigmoid függvény Pythonban]
def sigmoid(self, x):
    return 1.0 / (1.0 + numpy.exp(-x))
    
def sigmoid_prime(z):
    """A sigmoid függvény deriváltja"""
    return sigmoid(z)*(1-sigmoid(z))
    
\end{lstlisting}

\paragraph{}
Mint azt ahogyan a fenti 5.7-es kódrészletben láthatjuk, az alkamazás 4 rétegből áll:  egy 90 neuronból álló INPUT LAYER, egy 2 neuronból álló OUTPUT LAYER, és a köztük léve 20 és 8 neuronokból álló köztes layerek(HIDDEN LAYERS). Az alkalmazásban használt neurális háló felépítését a 2. fejezetben megjelenő 2.2-es ábrán tekinthetjük meg.

\paragraph{}
A már a fentiekben is tárgyalt, és a 5.8-as kódrészletben Python alakban is megtalálható szigmoid függvényt a "feedforward" metódus használja, amelyek a Network osztályunk metóduskészletéből származnak.

\begin{lstlisting}[caption=A Network osztály konstruktora illetve a feedforward függvény]
class Network(object):
    def __init__(self, sizes):
        self.layers = len(sizes)
        self.sizes = sizes
        self.biases = [numpy.random.randn(x, 1) for x in sizes[1:]]
        self.weights = [numpy.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]
        self.data = []
        self.max_biases = []
        self.max_weights = []
        self.max_percentage = 0.0
        self.history = []

    def feedforward(self, a):
        """Return the output of the network if "a" is input."""
        for bias, weight in zip(self.biases, self.weights):
            a = self.sigmoid(numpy.dot(weight, a) + bias)
        return a
        
    ...  
\end{lstlisting}

Mint ahogyan a fenti 5.9-es kódrészletből is láthatjuk, a tömbben tárolandó adatok tárolásához a Python Numpy könyvtárát használjuk fel. Kezdetben a súlyokat és a bias értékeit random adatokkal töltsük fel, majd ahogyan a továbbiakban meglátjuk, ezeken az értékeken folyamatos apró módosításokat fogunk végrehajtani az eredményesség növelése érdekében.

\paragraph{}
A "feedforward" metódus egy, a paraméterként megadott (a) érték függvényében egy outputot fog visszatéríteni abban az esetben, ha a paraméterként megadott érték egy érvényes input adat.

\paragraph{}
És akkor most lássuk, hogyan is működik a tanulási/training folyamat:
\begin{lstlisting}[caption= A train függvény]
def train(self, data, eta, weight_filename, biases_filename):
        j = 0
        self.history = []
        while j < NR_OF_EPOCH:
            j += 1
            self.update(data, eta)
            right = self.evaluate(data)
            whole = len(data)
            cur = right / whole
            print("Epoch", j, ":", cur*100, "%")
            self.history.append(cur*100)
            if cur > self.max_percentage:
                self.max_percentage = cur
                self.max_biases = self.biases
                self.max_weights = self.weights

        self.write_weights_to_file(self.max_weights, weight_filename)    
        self.write_biases_to_file(self.max_biases, biases_filename)
        self.max_percentage = self.max_percentage*100
        print("Max percentage = ", self.max_percentage, "%")
\end{lstlisting}

A függvény (5.10-es kódrészlet) első fontos paramétere a "data" egy (inputs, outputs) párok listája, amelyek a tréning bemenő adatait és az eredményt (a győztest), azaz a kimeneti adatokat is tartalmazza. Ennek a szerkezete a következő:

\begin{lstlisting}[caption= A data-paraméter egy eleme]
{
  "outputs":[1,0],
  "inputs":[0.63,0.74,0.63,0.72,0.6,0.68,0.53,0.55,0.61,0.67,0.53,0.55,0.0,1.0 ...]
}
\end{lstlisting}

Az "eta" a learning rate-nek felel meg, amelynek megválasztása nagyon is fontos, mert egy esetleges rossz érték választása nagyban eltorzíthatja, elronthatja a várt eredményt.
 
Az utolsó két paraméter (weight-filename, biases-filename) mint ahogyan a nevükből is kikövetkeztethető, az állományok nevét tartalmazzák, amelyekben a végső súlyokat és bias-eket fogjuk tárolni/kiírni. A tanulás folyamat egy előre meghatározott számú(NR OF EPOCH) alkalommal végrehajtott programblokkból áll, ugyanakkor annak érdekében, hogy a lehető legjobb beállításokat tartsuk meg, minden iteráció végén összehasonlítjuk az eredményeket, és a jobbat lementjük.
\paragraph{}
Minden iteréció alkalmával frissítjük (5.13) a súlyokat (weights) és a torzításokat (bias). Ha a training adatok rendelkezésre állnak, akkor a program minden iteráció alkalmával kiértékeli a hálózatot, amelyet az "evaluate" függvénnyel teszi (5.12-es kódrészlet). A kimeneti adatok alapján tudja majd ez a függvény eldönteni, hogy az álta megtippelt eredmény helyes volt vagy sem, amelynek függvényében más és más módosításokat eszközöl a beállításokon(weights, biases). Mindezek mellet a függvény minden körben kiírja a haladást (a háló pontosságát, hogy az összes mérkőzés/traning adat közül hányat tippelt meg helyesen, azaz hogy ezt milyen arányban tette: cur = right / whole). Ez természetesen bizonyos mértékben lassítja a program futását, növeli annak futási idejét, viszont nagyon hasznos és sokatmondó is egyben.

\begin{lstlisting}[caption= A neurális hálót kiértékelő függvény]
def evaluate(self, data):
    test_results = [(numpy.argmax(self.feedforward(x)), y) for (x, y) in data]
    return sum(int(x == numpy.argmax(y)) for (x, y) in test_results)
\end{lstlisting}

\begin{lstlisting}[caption= A neurális hálót kiértékelő függvény]
def update(self, data, eta):
  dif_bias = [numpy.zeros(b.shape) for b in self.biases]
  dif_weight = [numpy.zeros(w.shape) for w in self.weights]
  for x, y in data:
    delta_dif_bias, delta_dif_weight = self.backpropagation(x, y)
    dif_bias = [newbias + difnewbias for newbias, difnewbias in zip(dif_bias, delta_dif_bias)]
    dif_weight = [newweight + difnewweight for newweight, difnewweight in zip(dif_weight, delta_dif_weight)]
  self.weights = [weight - (eta / len(data)) * newweight for weight, newweight in zip(self.weights, dif_weight)]
  self.biases = [bias - (eta / len(data)) * newbias for bias, newbias in zip(self.biases, dif_bias)]
\end{lstlisting}

\paragraph{}
Mint ahogyan már a fentiekben is említettük, az 5.13-as kódrészletben szereplő update függvény a felelős a súlyok és a torzítások frissítésében. Ennek a metódusnak a legfontosabb sora a következő: \\
\begin{lstlisting}[caption=]
delta_dif_bias, delta_dif_weight = self.backpropagation(x, y)
\end{lstlisting}
\paragraph{}
Itt hívja meg az úgynevezett backpropagation algoritmust (5.14), amelynek működésének a megértése egy elég komoly matematikai tudást feltételez és igényel, viszont ebben a dolgozatban nem megyünk ennek az algoritmusnak a működésébe. Tulajdonképpen ez az algoritmus egy gyors módszer a költségfüggvény gradiensének a kiszámításához, amely függvényében az update nevű függvényünk a megfelelő módon frissíti a súlyok és a torzítások értékeit.

\begin{lstlisting}[caption=A backpropagation algoritmus]
    def backpropagation(self, x, y):
        dif_bias = [numpy.zeros(bias.shape) for bias in self.biases]
        dif_weight = [numpy.zeros(weight.shape) for weight in self.weights]
        activation = x
        activations = [x]
        results = []
        for bias, weight in zip(self.biases, self.weights):
            result = numpy.dot(weight, activation) + bias
            results.append(result)
            activation = self.sigmoid(result)
            activations.append(activation)
        delta = self.cost_derivative(activations[-1], y) * self.sigmoid_prime(results[-1])
        dif_bias[-1] = delta
        dif_weight[-1] = numpy.dot(delta, activations[-2].transpose())
        for l in range(2, self.layers):
            result = results[-l]
            sp = self.sigmoid_prime(result)
            delta = numpy.dot(self.weights[-l + 1].transpose(), delta) * sp
            dif_bias[-l] = delta
            dif_weight[-l] = numpy.dot(delta, activations[-l - 1].transpose())
        return (dif_bias, dif_weight)
\end{lstlisting}

\paragraph{}
A training végeztével a kiszámolt és a folyamatosan javított súlyokat és torzításokat egy-egy állományba mentjük, amelyeket majd újra beolvasunk és Numpy tömbök formájában újra felépítünk. Ezeket az tömböket (self.weights, self.biases) fogjuk használni egy egy párharc megjósolása érdekében:

\begin{lstlisting}[caption=A Predict Controller a Python szerver esetén:]
@app.route('/prediction', methods=['POST'])
def predict():
    network = Network([NR_OF_INPUTS, NR_OF_LAY, NR_OF_OUTPUTS])
    network.set_weights_and_biases(add_relative_path(request.json['weights_filename']), add_relative_path(request.json['biases_filename']), False)
    
    numpy_inputs = convert_data_to_input_data(request.json['inputs'])
    resp_data = network.feedforward(numpy_inputs)

    numpy_inputs_revert = convert_data_to_input_data(revert_input_data(request.json['inputs']))
    resp_data_invert = network.feedforward(numpy_inputs_revert)

    percentage1 = ((resp_data[0][0] + resp_data_invert[1][0]) / 2) * 100
    percentage2 = ((resp_data[1][0] + resp_data_invert[0][0]) / 2) * 100

    to_json = {}
    to_json['first_percentage']  = percentage1
    to_json['second_percentage'] = percentage2
	
    return app.response_class(
        response=json.dumps(to_json),
        status=200,
        mimetype='application/json'
    )    
\end{lstlisting}

\paragraph{}
A fenti Python Controller által kiszámított valószinűségeket egy JSON objektummá alakítjuk, majd visszaküldjük a Java alapú szerverünknek. Az majd megpróbálja értelmezni a kapott választ, majd továbbítja azt a kliens oldal irányába (5.16-os kódrészlet).

\begin{lstlisting}[caption=Szerverek közti kommunikáció]
PredictionRequestDTO requestDTO = 
	new PredictionRequestDTO(playerOne.getPlayerSlug(), 
			playerTwo.getPlayerSlug(), 
			weight_filename,
			biases_filename, 
			getInputsToPredict(playerOne, playerTwo, surface, tourneyName));
			
HttpEntity<PredictionRequestDTO> request = new HttpEntity<>(requestDTO);
ResponseEntity<PredictionResponseDTO> response;

try{
    response = restTemplate.postForEntity(URL, request, PredictionResponseDTO.class);
    PredictionResponseDTO responseDTO = response.getBody();
        return predicterService.convertSumToOneHundredPercent(
          responseDTO.getFirst_percentage(),responseDTO.getSecond_percentage());
} catch (Exception e){
    System.out.println(e);
    return Arrays.asList(50, 50);
}
\end{lstlisting}